{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tratamento_de_Dados.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNy2wJB0LjDVUCMxf1b5s/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisFTacla/WDW_Attendance_Calculator/blob/main/Tratamento_de_Dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddlfOwz_fofc",
        "outputId": "1abb1059-ccbc-4d74-8aa7-d0ff9143ea42"
      },
      "source": [
        "# IMPORTANDO BIBLIOTECAS\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import scipy.interpolate as interpolate\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "# LENDO URI\n",
        "uri_01 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/splash_mountain.csv'\n",
        "uri_02 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/pirates_of_caribbean.csv'\n",
        "uri_03 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/7_dwarfs_train.csv'\n",
        "uri_04 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/soarin.csv'\n",
        "uri_05 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/spaceship_earth.csv'\n",
        "uri_06 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/rock_n_rollercoaster.csv'\n",
        "uri_07 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/toy_story_mania.csv'\n",
        "uri_08 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/slinky_dog.csv'\n",
        "uri_09 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/alien_saucers.csv'\n",
        "uri_10 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/kilimanjaro_safaris.csv'\n",
        "uri_11 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/dinosaur.csv'\n",
        "uri_12 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/expedition_everest.csv'\n",
        "uri_13 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/flight_of_passage.csv'\n",
        "uri_14 = 'https://raw.githubusercontent.com/LuisFTacla/WDW_Attendance_Calculator/main/Dados/TouringPlans/Rides/Raw_Data/navi_river.csv'\n",
        "\n",
        "# LENDO ARQUIVOS\n",
        "mk_01 = pd.read_csv(uri_01)\n",
        "mk_02 = pd.read_csv(uri_02)\n",
        "mk_03 = pd.read_csv(uri_03)\n",
        "ep_01 = pd.read_csv(uri_04)\n",
        "ep_02 = pd.read_csv(uri_05)\n",
        "hs_01 = pd.read_csv(uri_06)\n",
        "hs_02 = pd.read_csv(uri_07)\n",
        "hs_03 = pd.read_csv(uri_08)\n",
        "hs_04 = pd.read_csv(uri_09)\n",
        "ak_01 = pd.read_csv(uri_10)\n",
        "ak_02 = pd.read_csv(uri_11)\n",
        "ak_03 = pd.read_csv(uri_12)\n",
        "ak_04 = pd.read_csv(uri_13)\n",
        "ak_05 = pd.read_csv(uri_14)\n",
        "\n",
        "# DICIONARIO COM NOMES DAS ATRACOES\n",
        "nome_das_atracoes = {1: 'Splash Mountain',\n",
        "                     2: 'Pirates of Caribbean',\n",
        "                     3: 'Seven Dwarfs Mine Train',\n",
        "                     4: 'Soarin',\n",
        "                     5: 'Spaceship Earth',\n",
        "                     6: 'Rock n Roller Coaster',\n",
        "                     7: 'Toy Story Mania',\n",
        "                     8: 'Slinky Dog Dash',\n",
        "                     9: 'Alien Saucers',                \n",
        "                     10: 'Kilimanjaro Safari',\n",
        "                     11: 'Dinosaur',\n",
        "                     12: 'Expedition Everest',\n",
        "                     13: 'Avatar: Flight of Passage',\n",
        "                     14: 'Navi River'}\n",
        "\n",
        "# DICIONARIO COM DATAFRAMES\n",
        "datasets_das_atracoes = {1: mk_01,\n",
        "                         2: mk_02,\n",
        "                         3: mk_03,\n",
        "                         4: ep_01,\n",
        "                         5: ep_02,\n",
        "                         6: hs_01,\n",
        "                         7: hs_02,\n",
        "                         8: hs_03,\n",
        "                         9: hs_04,\n",
        "                         10: ak_01,\n",
        "                         11: ak_02,\n",
        "                         12: ak_03,\n",
        "                         13: ak_04,\n",
        "                         14: ak_05}\n",
        "\n",
        "# FUNCOES PARA O TRATAMENTO DOS DADOS\n",
        "def remove_sactmin(dados):\n",
        "  dados.drop(columns = ['SACTMIN'], inplace = True)\n",
        "  return dados\n",
        "\n",
        "def remove_dados_ausentes(dados):\n",
        "  dados.dropna(inplace= True)\n",
        "  return dados\n",
        "\n",
        "def to_datetime(dados):\n",
        "  dados['data_e_hora'] = pd.to_datetime(dados['datetime'])\n",
        "  return dados\n",
        "\n",
        "def cria_coluna_tempo_de_fila(dados):\n",
        "  dados['tempo_de_fila'] = dados['SPOSTMIN']\n",
        "  return dados\n",
        "\n",
        "def remove_colunas(dados):\n",
        "  dados.drop(columns = ['SPOSTMIN', 'date', 'datetime'], inplace = True)\n",
        "  return dados\n",
        "\n",
        "def reset_index(dados):\n",
        "  dados.reset_index(drop = True, inplace = True)\n",
        "  return dados\n",
        "\n",
        "def coluna_apagar(dados):\n",
        "  dados['apagar'] = 0\n",
        "  return dados\n",
        "\n",
        "def remove_coluna_apagar(dados):\n",
        "  dados.drop(columns = ['apagar'], inplace = True)\n",
        "  return dados\n",
        "\n",
        "def tratamento_dados(dados):\n",
        "  remove_sactmin(dados)\n",
        "  remove_dados_ausentes(dados)\n",
        "  to_datetime(dados)\n",
        "  cria_coluna_tempo_de_fila(dados)\n",
        "  remove_colunas(dados)\n",
        "  reset_index(dados)\n",
        "  coluna_apagar(dados)\n",
        "\n",
        "# EXECUTANDO AS FUNCOES PARA CADA ATRACAO\n",
        "for i in range(1,15):\n",
        "  tratamento_dados(datasets_das_atracoes[i])\n",
        "\n",
        "# FILTRANDO DADOS\n",
        "for i in range(1,15):\n",
        "  filtro = datasets_das_atracoes[i].tempo_de_fila >= 0\n",
        "  datasets_das_atracoes[i] = datasets_das_atracoes[i][filtro]\n",
        "\n",
        "# CRIANDO DATAFRAME BASE\n",
        "bases = {}\n",
        "instantes_5_em_5 = pd.date_range(start='1/1/2015', periods = 525888, \n",
        "                                 freq = '5min')\n",
        "for i in range(1,15): \n",
        "  bases[i] = pd.DataFrame(index = range(0,525888), columns = ['data_e_hora', \n",
        "                                                              'tempo_de_fila', \n",
        "                                                              'apagar'])\n",
        "  bases[i]['data_e_hora'] = instantes_5_em_5\n",
        "  bases[i]['tempo_de_fila'] = 0\n",
        "  bases[i]['apagar'] = 0\n",
        "  bases[i]['observacao'] = bases[i].index\n",
        "  bases[i].set_index('observacao', inplace = True)\n",
        "\n",
        "# UNINDO DATAFRAMES AO BASE\n",
        "datasets_das_atracoes_2 = {}\n",
        "\n",
        "for i in range(1,15):\n",
        "  datasets_das_atracoes_2[i] = bases[i].append(datasets_das_atracoes[i])\n",
        "\n",
        "# ORDENANDO POR DATA/HORA\n",
        "for i in range(1,15):\n",
        "  datasets_das_atracoes_2[i].sort_values(by=['data_e_hora'], inplace = True)\n",
        "\n",
        "# RESETANDO INDICE\n",
        "for i in range(1,15):\n",
        "  reset_index(datasets_das_atracoes_2[i])\n",
        "\n",
        "# SELECIONANDO LINHAS PARA APAGAR\n",
        "for j in range(1,15):\n",
        "  dados_e_base_df = datasets_das_atracoes_2[j]\n",
        "  for i in range(0,len(dados_e_base_df)):\n",
        "    C1 = i != 0\n",
        "    C2 = i != 1\n",
        "    C3 = i != (len(dados_e_base_df) - 1)\n",
        "    C4 = i != (len(dados_e_base_df) - 2)\n",
        "    if C1 and C2 and C3 and C4:\n",
        "      if (dados_e_base_df.tempo_de_fila[i] == 0):\n",
        "        c1 = (dados_e_base_df.tempo_de_fila[i + 1] != 0)\n",
        "        c2 = (dados_e_base_df.tempo_de_fila[i - 1] != 0)\n",
        "        c3 = (dados_e_base_df.tempo_de_fila[i + 2] != 0)\n",
        "        c4 = (dados_e_base_df.tempo_de_fila[i - 2] != 0)\n",
        "        if c1 or c2 or c3 or c4:\n",
        "          dados_e_base_df.apagar[i] = 1\n",
        "    datasets_das_atracoes_2[j] = dados_e_base_df\n",
        "  print('Opa! Terminei a leitura da atração {}!'.format(nome_das_atracoes[j]))\n",
        "print('Pronto!! Terminei essa etapa!!')\n",
        "\n",
        "# APAGANDO LINHAS\n",
        "for i in range(1,15):\n",
        "  filtro2 = datasets_das_atracoes_2[i].apagar == 0\n",
        "  datasets_das_atracoes_2[i] = datasets_das_atracoes_2[i][filtro2]\n",
        "\n",
        "# INTERPOLANDO TEMPOS DE FILA\n",
        "datasets_das_atracoes_3 = {}\n",
        "\n",
        "for i in range(1,15):\n",
        "\n",
        "  datasets_das_atracoes_3[i] = bases[i]\n",
        "\n",
        "  X_interp = bases[i].data_e_hora\n",
        "  X = datasets_das_atracoes_2[i].data_e_hora\n",
        "  Y = datasets_das_atracoes_2[i].tempo_de_fila\n",
        "  \n",
        "  Y_interp = np.interp(X_interp, X, Y)\n",
        "\n",
        "  datasets_das_atracoes_3[i].tempo_de_fila = np.around(Y_interp, decimals = 0)\n",
        "\n",
        "# APAGANDO COLUNA 'APAGAR'\n",
        "for i in range(1,15):\n",
        "  remove_coluna_apagar(datasets_das_atracoes_3[i])\n",
        "\n",
        "# CRIANDO COLUNA 'STATUS'\n",
        "\n",
        "for i in range(1,15):\n",
        "  datasets_das_atracoes_3[i]['status'] = 0\n",
        "\n",
        "for i in range(1,15):\n",
        "  for j in range(0,525888):\n",
        "      if datasets_das_atracoes_3[i].tempo_de_fila[j] != 0:\n",
        "        datasets_das_atracoes_3[i].status[j] = 1\n",
        "  print('Opa! Terminei a leitura da atração {}!'.format(nome_das_atracoes[i]))\n",
        "\n",
        "# SALVANDO OS DADOS TRATADOS\n",
        "datasets_das_atracoes_3[1].to_csv((r'Splash_Mountain.csv'), index = False)\n",
        "datasets_das_atracoes_3[2].to_csv((r'Pirates_of_Caribbean.csv'), index = False)\n",
        "datasets_das_atracoes_3[3].to_csv((r'Seven_Dwarfs_Mine_Train.csv'), index = False)\n",
        "datasets_das_atracoes_3[4].to_csv((r'Soarin.csv'), index = False)\n",
        "datasets_das_atracoes_3[5].to_csv((r'Spaceship_Earth.csv'), index = False)\n",
        "datasets_das_atracoes_3[6].to_csv((r'Rock_n_Roller_Coaster.csv'), index = False)\n",
        "datasets_das_atracoes_3[7].to_csv((r'Toy_Story_Mania.csv'), index = False)\n",
        "datasets_das_atracoes_3[8].to_csv((r'Slinky_Dog_Dash.csv'), index = False)\n",
        "datasets_das_atracoes_3[9].to_csv((r'Alien_Saucers.csv'), index = False)\n",
        "datasets_das_atracoes_3[10].to_csv((r'Kilimanjaro_Safari.csv'), index = False)\n",
        "datasets_das_atracoes_3[11].to_csv((r'Dinosaur.csv'), index = False)\n",
        "datasets_das_atracoes_3[12].to_csv((r'Expedition_Everest.csv'), index = False)\n",
        "datasets_das_atracoes_3[13].to_csv((r'Avatar_Flight_of_Passage.csv'), index = False)\n",
        "datasets_das_atracoes_3[14].to_csv((r'Navi_River.csv'), index = False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:168: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Opa! Terminei a leitura da atração Splash Mountain!\n",
            "Opa! Terminei a leitura da atração Pirates of Caribbean!\n",
            "Opa! Terminei a leitura da atração Seven Dwarfs Mine Train!\n",
            "Opa! Terminei a leitura da atração Soarin!\n",
            "Opa! Terminei a leitura da atração Spaceship Earth!\n",
            "Opa! Terminei a leitura da atração Rock n Roller Coaster!\n",
            "Opa! Terminei a leitura da atração Toy Story Mania!\n",
            "Opa! Terminei a leitura da atração Slinky Dog Dash!\n",
            "Opa! Terminei a leitura da atração Alien Saucers!\n",
            "Opa! Terminei a leitura da atração Kilimanjaro Safari!\n",
            "Opa! Terminei a leitura da atração Dinosaur!\n",
            "Opa! Terminei a leitura da atração Expedition Everest!\n",
            "Opa! Terminei a leitura da atração Avatar: Flight of Passage!\n",
            "Opa! Terminei a leitura da atração Navi River!\n",
            "Pronto!! Terminei essa etapa!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Opa! Terminei a leitura da atração Splash Mountain!\n",
            "Opa! Terminei a leitura da atração Pirates of Caribbean!\n",
            "Opa! Terminei a leitura da atração Seven Dwarfs Mine Train!\n",
            "Opa! Terminei a leitura da atração Soarin!\n",
            "Opa! Terminei a leitura da atração Spaceship Earth!\n",
            "Opa! Terminei a leitura da atração Rock n Roller Coaster!\n",
            "Opa! Terminei a leitura da atração Toy Story Mania!\n",
            "Opa! Terminei a leitura da atração Slinky Dog Dash!\n",
            "Opa! Terminei a leitura da atração Alien Saucers!\n",
            "Opa! Terminei a leitura da atração Kilimanjaro Safari!\n",
            "Opa! Terminei a leitura da atração Dinosaur!\n",
            "Opa! Terminei a leitura da atração Expedition Everest!\n",
            "Opa! Terminei a leitura da atração Avatar: Flight of Passage!\n",
            "Opa! Terminei a leitura da atração Navi River!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D4_VOz2HGy_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}